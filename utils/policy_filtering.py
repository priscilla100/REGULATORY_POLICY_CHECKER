"""
PRODUCTION-READY POLICY FILTERING SYSTEM
For handling 1000+ HIPAA policies and diverse natural language queries

Key improvements:
1. Semantic embeddings (not just keywords)
2. Hybrid scoring (semantic + keyword + heuristic)
3. Query expansion for robustness
4. Tiered filtering (coarse â†’ fine)
5. Fallback mechanisms
"""

import numpy as np
from typing import List, Dict, Tuple, Set
from sentence_transformers import SentenceTransformer
from rank_bm25 import BM25Okapi
import re

from anthropic import Anthropic

# ============================================================================
# PRODUCTION-GRADE POLICY FILTER AGENT
# ============================================================================

class ProductionPolicyFilterAgent:
    """
    Scalable policy filtering for 1000+ policies
    
    Uses hybrid approach:
    - Semantic embeddings (handles paraphrasing)
    - BM25 keyword matching (handles exact terms)
    - Heuristic rules (handles edge cases)
    """
    
    def __init__(self, embedding_model: str = 'sentence-transformers/all-mpnet-base-v2'):
        """
        Initialize with embedding model
        
        First run downloads ~400MB model, then cached
        """
        print("ðŸ”„ Loading semantic model for policy filtering...")
        self.embedding_model = SentenceTransformer(embedding_model)
        print("âœ… Model loaded")
        
        # Will be initialized when policies are loaded
        self.policy_embeddings = None
        self.bm25_index = None
        self.policies = None
        self.policy_texts = None
    
    def index_policies(self, policies: List[Dict]) -> None:
        """
        Index policies for fast retrieval
        
        Run this ONCE at startup, then reuse for all queries
        """
        print(f"ðŸ“Š Indexing {len(policies)} policies...")
        
        self.policies = policies
        
        # Create rich text representations
        self.policy_texts = [
            self._create_policy_text(p) for p in policies
        ]
        
        # Create semantic embeddings
        print("   Generating embeddings...")
        self.policy_embeddings = self.embedding_model.encode(
            self.policy_texts,
            show_progress_bar=True,
            convert_to_numpy=True
        )
        
        # Create BM25 index
        print("   Building BM25 index...")
        tokenized = [text.lower().split() for text in self.policy_texts]
        self.bm25_index = BM25Okapi(tokenized)
        
        print(f"âœ… Indexed {len(policies)} policies")
    
    def _create_policy_text(self, policy: Dict) -> str:
        """
        Create rich text representation of policy for better matching
        
        Combines: section, title, description, keywords
        """
        parts = []
        
        # Section number (important for exact citations)
        if 'section' in policy:
            parts.append(policy['section'])
        
        # Title/category
        if 'title' in policy:
            parts.append(policy['title'])
        elif 'category' in policy:
            parts.append(policy['category'])
        
        # Description
        if 'description' in policy:
            parts.append(policy['description'])
        
        # Natural language text
        if 'text' in policy:
            parts.append(policy['text'])
        elif 'natural_language' in policy:
            parts.append(policy['natural_language'])
        
        return ' '.join(parts)
    
    def filter_policies(
        self,
        query: str,
        top_k: int = 30,
        exclude_organizational: bool = True
    ) -> List[Dict]:
        """
        Filter policies to only relevant ones
        
        Args:
            query: User's question
            top_k: Number of policies to return (default 30)
            exclude_organizational: Auto-filter organizational policies (default True)
        
        Returns:
            List of relevant policies, scored and ranked
        """
        
        if self.policies is None:
            raise ValueError("Must call index_policies() first!")
        
        # Step 1: Expand query for better matching
        expanded_query = self._expand_query(query)
        
        # Step 2: Hybrid scoring (semantic + keyword + heuristic)
        scores = self._compute_hybrid_scores(query, expanded_query)
        
        # Step 3: Apply filters
        if exclude_organizational:
            scores = self._filter_organizational(query, scores)
        
        # Step 4: Get top-k
        top_indices = np.argsort(scores)[-top_k:][::-1]
        
        # Step 5: Return policies with scores
        results = []
        for idx in top_indices:
            if scores[idx] > 0:  # Only return policies with positive scores
                policy = self.policies[idx].copy()
                policy['relevance_score'] = float(scores[idx])
                results.append(policy)
        
        return results
    
    def _expand_query(self, query: str) -> str:
        """
        Expand query with synonyms and related terms
        
        Improves recall for paraphrased questions
        """
        query_lower = query.lower()
        expansions = []
        
        # Medical term expansions
        expansions_map = {
            'doctor': ['physician', 'provider', 'clinician', 'practitioner'],
            'patient': ['individual', 'person', 'subject'],
            'share': ['disclose', 'provide', 'give access', 'transmit', 'release'],
            'record': ['information', 'data', 'PHI', 'protected health information'],
            'consent': ['authorization', 'permission', 'agreement'],
            'hospital': ['covered entity', 'healthcare provider', 'facility'],
            'allowed': ['permitted', 'authorized', 'may', 'can'],
            'required': ['must', 'shall', 'mandatory', 'obligated'],
            'grandma': ['family member', 'relative', 'next of kin'],
            'researcher': ['investigator', 'research', 'study'],
        }
        
        for term, synonyms in expansions_map.items():
            if term in query_lower:
                expansions.extend(synonyms)
        
        # Acronym expansion
        acronyms = {
            'tpo': 'treatment payment healthcare operations',
            'phi': 'protected health information',
            'ehr': 'electronic health record',
            'ba': 'business associate',
            'ce': 'covered entity',
        }
        
        for acronym, expansion in acronyms.items():
            if acronym in query_lower.split():
                expansions.append(expansion)
        
        return query + ' ' + ' '.join(expansions)
    
    def _compute_hybrid_scores(self, query: str, expanded_query: str) -> np.ndarray:
        """
        Compute hybrid relevance scores combining multiple signals
        
        Returns: Array of scores (one per policy)
        """
        N = len(self.policies)
        
        # 1. Semantic similarity (70% weight)
        query_embedding = self.embedding_model.encode([expanded_query])[0]
        semantic_scores = np.dot(self.policy_embeddings, query_embedding)
        semantic_scores = self._normalize(semantic_scores)
        
        # 2. BM25 keyword matching (20% weight)
        tokenized_query = expanded_query.lower().split()
        bm25_scores = self.bm25_index.get_scores(tokenized_query)
        bm25_scores = self._normalize(bm25_scores)
        
        # 3. Heuristic boosting (10% weight)
        heuristic_scores = np.zeros(N)
        for i, policy in enumerate(self.policies):
            heuristic_scores[i] = self._compute_heuristic_score(query, policy)
        heuristic_scores = self._normalize(heuristic_scores)
        
        # Combine with weights
        final_scores = (
            0.7 * semantic_scores +
            0.2 * bm25_scores +
            0.1 * heuristic_scores
        )
        
        return final_scores
    
    def _normalize(self, scores: np.ndarray) -> np.ndarray:
        """Min-max normalization to [0, 1]"""
        if scores.max() == scores.min():
            return np.ones_like(scores)
        return (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
    
    def _compute_heuristic_score(self, query: str, policy: Dict) -> float:
        """
        Rule-based scoring for edge cases
        
        Handles things semantic/keyword matching might miss
        """
        score = 0.0
        query_lower = query.lower()
        
        # Exact section citation in query
        section = policy.get('section', '').lower()
        if section and section in query_lower:
            score += 10.0  # Strong boost for exact citations
        
        # Exact policy ID in query
        policy_id = policy.get('policy_id', '').lower()
        if policy_id and policy_id in query_lower:
            score += 10.0
        
        # Foundational policies (always somewhat relevant)
        foundational_ids = ['hipaa-0', 'hipaa-1', 'hipaa-2', 'hipaa-3']
        if policy_id in foundational_ids:
            score += 2.0
        
        # Question type matching
        desc = policy.get('description', '').lower()
        
        # Treatment questions â†’ treatment policies
        if any(word in query_lower for word in ['treatment', 'care', 'doctor', 'physician']):
            if any(word in desc for word in ['treatment', 'tpo', 'healthcare operations']):
                score += 3.0
        
        # Authorization questions â†’ authorization policies
        if any(word in query_lower for word in ['consent', 'authorization', 'permission']):
            if 'authorization' in desc or 'consent' in desc:
                score += 3.0
        
        # Research questions â†’ research policies
        if 'research' in query_lower:
            if 'research' in desc:
                score += 3.0
        
        # Family access questions â†’ disclosure policies
        if any(word in query_lower for word in ['family', 'relative', 'grandma', 'parent', 'spouse']):
            if any(word in desc for word in ['family', 'relatives', 'disclosure to']):
                score += 3.0
        
        return score
    
    def _filter_organizational(self, query: str, scores: np.ndarray) -> np.ndarray:
        """
        Filter out organizational policies unless explicitly asked about them
        
        This prevents the "7 violations" issue
        """
        query_lower = query.lower()
        
        # Check if user is asking about organizational compliance
        organizational_queries = [
            'organizational', 'compliance program', 'privacy officer',
            'security officer', 'policies and procedures', 'safeguards',
            'training requirements', 'administrative requirements',
            'comprehensive audit', 'full compliance check'
        ]
        
        asking_about_org = any(phrase in query_lower for phrase in organizational_queries)
        
        if asking_about_org:
            return scores  # Don't filter, user wants org policies
        
        # Filter out organizational policies
        organizational_keywords = [
            'privacy official', 'privacy officer', 'security official',
            'security officer', 'personnel designation', 'workforce',
            'training', 'safeguard', 'policies and procedures',
            'complaint process', 'evaluation', 'incident response',
            'documentation', 'sanction', 'mitigation', 'retention',
            'risk analysis', 'contingency plan', 'disaster recovery',
            'access control', 'audit control', 'integrity control',
            'transmission security', 'facility security', 'workstation'
        ]
        
        filtered_scores = scores.copy()
        
        for i, policy in enumerate(self.policies):
            desc = policy.get('description', '').lower()
            policy_id = policy.get('policy_id', '')
            
            # Check if organizational policy
            is_org = any(kw in desc for kw in organizational_keywords)
            
            # Also check policy ID range (organizational policies are typically 29-87)
            if policy_id.startswith('HIPAA-'):
                try:
                    num = int(policy_id.split('-')[1])
                    if 29 <= num <= 87:
                        is_org = True
                except:
                    pass
            
            # Penalize organizational policies heavily
            if is_org:
                filtered_scores[i] *= 0.1  # Reduce score by 90%
        
        return filtered_scores
    
    def get_statistics(self, filtered_policies: List[Dict]) -> Dict:
        """Get statistics about filtered policies"""
        
        if not filtered_policies:
            return {
                'total_policies': len(self.policies),
                'filtered_count': 0,
                'avg_score': 0.0,
                'min_score': 0.0,
                'max_score': 0.0
            }
        
        scores = [p.get('relevance_score', 0.0) for p in filtered_policies]
        
        return {
            'total_policies': len(self.policies),
            'filtered_count': len(filtered_policies),
            'avg_score': np.mean(scores),
            'min_score': np.min(scores),
            'max_score': np.max(scores),
            'score_distribution': {
                'high (>0.8)': sum(1 for s in scores if s > 0.8),
                'medium (0.5-0.8)': sum(1 for s in scores if 0.5 <= s <= 0.8),
                'low (<0.5)': sum(1 for s in scores if s < 0.5)
            }
        }


# ============================================================================
# INTEGRATION WITH EXISTING SYSTEM
# ============================================================================

class RobustPolicyFilterAgent:
    """
    Drop-in replacement for PolicyFilterAgent
    Uses production-grade filtering under the hood
    """
    
    def __init__(self, client: Anthropic = None):
        """Initialize with optional Anthropic client for LLM fallback"""
        self.client = client
        self.production_filter = ProductionPolicyFilterAgent()
        self.indexed = False
    
    def filter_policies(
        self,
        query: str,
        all_policies: List[Dict],
        top_k: int = 30
    ) -> List[Dict]:
        """
        Filter policies using hybrid semantic + keyword matching
        
        Args:
            query: User's question
            all_policies: Complete policy database
            top_k: Number of policies to return
        
        Returns:
            Filtered and ranked policies
        """
        
        # Index policies if not already done
        if not self.indexed:
            self.production_filter.index_policies(all_policies)
            self.indexed = True
        
        # Filter using production-grade system
        filtered = self.production_filter.filter_policies(
            query=query,
            top_k=top_k,
            exclude_organizational=True
        )
        
        # Log statistics
        stats = self.production_filter.get_statistics(filtered)
        print(f"ðŸ“Š Policy Filtering Stats:")
        print(f"   Total policies: {stats['total_policies']}")
        print(f"   Filtered to: {stats['filtered_count']}")
        print(f"   Avg relevance: {stats['avg_score']:.3f}")
        print(f"   Distribution: {stats['score_distribution']}")
        
        return filtered

